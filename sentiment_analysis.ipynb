{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sentiment_analysis.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1Aoa9S6UHgX4oDZYSZEbA0DbcaIzVFDx0","authorship_tag":"ABX9TyP3flP5aGCQIhuxqg5Ti5z8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"dqs8w_hGi1j2"},"source":["# Large Movie Review Dataset Sentiment Analysis"]},{"cell_type":"code","metadata":{"id":"sy70uIWnWSjC","executionInfo":{"status":"ok","timestamp":1617279296608,"user_tz":-480,"elapsed":787,"user":{"displayName":"Cheng Fred","photoUrl":"","userId":"07264614451557710222"}}},"source":["import numpy as np\n","import pandas as pd\n","import pickle\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","from sklearn.model_selection import train_test_split\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"euzesy85Z6zl","executionInfo":{"status":"ok","timestamp":1617279297851,"user_tz":-480,"elapsed":889,"user":{"displayName":"Cheng Fred","photoUrl":"","userId":"07264614451557710222"}}},"source":["# read in the review text into lists\n","\n","reviews_train = []\n","for line in open('/content/drive/MyDrive/NLP_movie_review/aclImdb/movie_data/full_train.txt', 'r'):\n","    \n","    reviews_train.append(line.strip())\n","    \n","reviews_test = []\n","for line in open('/content/drive/MyDrive/NLP_movie_review/aclImdb/movie_data/full_test.txt', 'r'):\n","    \n","    reviews_test.append(line.strip())"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5XrSD0t34oEO","executionInfo":{"status":"ok","timestamp":1617279298167,"user_tz":-480,"elapsed":645,"user":{"displayName":"Cheng Fred","photoUrl":"","userId":"07264614451557710222"}},"outputId":"442d4fb5-0b26-4b57-d1fa-e35b90bdf176"},"source":["print(\"Length of Train set: \", len(reviews_train))\n","print(\"Length of Test set: \", len(reviews_test))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Length of Train set:  25000\n","Length of Test set:  25000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Z29N94Axeajz","executionInfo":{"status":"ok","timestamp":1617279298950,"user_tz":-480,"elapsed":938,"user":{"displayName":"Cheng Fred","photoUrl":"","userId":"07264614451557710222"}}},"source":["# prepare the target: 1 for positive and -1 for negative\n","\n","target = [1 if i < 12500 else -1 for i in range(25000)]"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":120},"id":"Vem38ok8aqR7","executionInfo":{"status":"ok","timestamp":1617279299405,"user_tz":-480,"elapsed":985,"user":{"displayName":"Cheng Fred","photoUrl":"","userId":"07264614451557710222"}},"outputId":"4436c4db-1b15-4042-d652-f20a6010d57e"},"source":["reviews_train[0]"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":120},"id":"USnptXfZarj9","executionInfo":{"status":"ok","timestamp":1617279299789,"user_tz":-480,"elapsed":853,"user":{"displayName":"Cheng Fred","photoUrl":"","userId":"07264614451557710222"}},"outputId":"7d975981-abeb-4fc2-9181-e3e3505b26f1"},"source":["reviews_test[88]"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"I am a huge fan of Harald Zwart, and I just knew that I had to see this movie, even though I can't say I'm a soccer fan. But watching this just filled my heart with joy, and I had a great time in the movies watching it.<br /><br />Bj√∏rn Fast Nagell does a tremendous job directing this movie, and even though you notice the main characters are new at acting, they grow with the movie and makes it what it is. Even though it is supposed to be a soccer movie, there is surprisingly little soccer in it. The whole idea is to show the six guys making up the word N O R W A Y on their trip to the World Cup in soccer playing in Germany this year. <br /><br />If you're only gonna see one Norwegian movie this year, this is the one..\""]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"siUJTsA3au0N","executionInfo":{"status":"ok","timestamp":1617279319477,"user_tz":-480,"elapsed":19979,"user":{"displayName":"Cheng Fred","photoUrl":"","userId":"07264614451557710222"}}},"source":["# regex for preprocessing the text, removing the space and punctuations, also turning words to lower case\n","\n","import re\n","\n","REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n","REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n","NO_SPACE = \"\"\n","SPACE = \" \"\n","\n","def preprocess_reviews(reviews):\n","    \n","    reviews = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in reviews]\n","    reviews = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in reviews]\n","    \n","    return reviews\n","\n","reviews_train_clean = preprocess_reviews(reviews_train)\n","reviews_test_clean = preprocess_reviews(reviews_test)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t6bOXvprkXyY"},"source":["# Logistic Regression 1\n","Using:\n","1. 1 to 3 ngram\n","2. a simplier list of stop words\n","3. Logistic Regression"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d5QaY7XUnnJI","executionInfo":{"status":"ok","timestamp":1617279894996,"user_tz":-480,"elapsed":594367,"user":{"displayName":"Cheng Fred","photoUrl":"","userId":"07264614451557710222"}},"outputId":"11c404a0-93a1-4a31-f4c8-d1fe90e63355"},"source":["from sklearn.linear_model import LogisticRegression\n","\n","stop_words = ['in', 'of', 'at', 'a', 'the'] # a more simple list of stop words\n","ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3), stop_words=stop_words) #using 1 to 3 ngrams\n","ngram_vectorizer.fit(reviews_train_clean)\n","train_set = ngram_vectorizer.transform(reviews_train_clean)\n","test_set = ngram_vectorizer.transform(reviews_test_clean)\n","\n","X_train = train_set\n","y_train = target\n","X_test, X_val, y_test, y_val = train_test_split(\n","      test_set, target, train_size = 0.5\n",")\n","\n","for c in [0.01, 0.05, 0.25, 0.5, 1]:\n","    \n","    lr = LogisticRegression(C=c)\n","    lr.fit(X_train, y_train)\n","    print (\"Accuracy for C=%s: %s\" \n","           % (c, accuracy_score(y_val, lr.predict(X_val))))\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Accuracy for C=0.01: 0.88576\n","Accuracy for C=0.05: 0.89512\n","Accuracy for C=0.25: 0.89624\n","Accuracy for C=0.5: 0.8964\n","Accuracy for C=1: 0.89656\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fIok6RItkXQS","executionInfo":{"status":"ok","timestamp":1617280043877,"user_tz":-480,"elapsed":111752,"user":{"displayName":"Cheng Fred","photoUrl":"","userId":"07264614451557710222"}},"outputId":"232a2450-352d-4ed7-d1d0-a5b969dfb988"},"source":["final_baseline = LogisticRegression(C=1) # taking c with highest accuracy\n","final_baseline.fit(X_train, y_train)\n","print (\"Final Accuracy of Best Model: %s\" \n","       % accuracy_score(y_test, final_baseline.predict(X_test)))\n","\n","print(\"Confusion Matrix of Best Model:\")\n","print(confusion_matrix(y_test, final_baseline.predict(X_test)))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Final Accuracy of Best Model: 0.9024\n","Confusion Matrix of Best Model:\n","[[5627  634]\n"," [ 586 5653]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cyOj32h0rAez"},"source":["# Logistic Regression 2\n","Using:\n","1. 1 to 3 ngram\n","2. a simplier list of stop words\n","3. Lemmatization\n","4. Logistic Regression"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KJPmEBM5q7nl","executionInfo":{"status":"ok","timestamp":1617280115294,"user_tz":-480,"elapsed":47470,"user":{"displayName":"Cheng Fred","photoUrl":"","userId":"07264614451557710222"}},"outputId":"7b3c4a96-c941-4993-9526-116b4c4ca36b"},"source":["# lemmatization for the corpus\n","\n","def get_lemmatized_text(corpus):\n","    \n","    import nltk\n","    nltk.download('wordnet')\n","    from nltk.stem import WordNetLemmatizer\n","    lemmatizer = WordNetLemmatizer()\n","    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n","\n","lemmatized_reviews_train = get_lemmatized_text(reviews_train_clean)\n","lemmatized_reviews_test = get_lemmatized_text(reviews_test_clean)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"APjIAiFxq7d9","executionInfo":{"status":"ok","timestamp":1617280744463,"user_tz":-480,"elapsed":590388,"user":{"displayName":"Cheng Fred","photoUrl":"","userId":"07264614451557710222"}},"outputId":"44e5785d-be75-4a1b-d04f-d61c3bbf71b8"},"source":["from sklearn.linear_model import LogisticRegression\n","\n","stop_words = ['in', 'of', 'at', 'a', 'the'] # a more simple list of stop words\n","ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3), stop_words=stop_words) #using 1 to 3 ngrams\n","ngram_vectorizer.fit(lemmatized_reviews_train)\n","train_set = ngram_vectorizer.transform(lemmatized_reviews_train)\n","test_set = ngram_vectorizer.transform(lemmatized_reviews_test)\n","\n","X_train = train_set\n","y_train = target\n","X_test, X_val, y_test, y_val = train_test_split(\n","      test_set, target, train_size = 0.5\n",")\n","\n","for c in [0.01, 0.05, 0.25, 0.5, 1]:\n","    \n","    lr = LogisticRegression(C=c)\n","    lr.fit(X_train, y_train)\n","    print (\"Accuracy for C=%s: %s\" \n","           % (c, accuracy_score(y_val, lr.predict(X_val))))\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Accuracy for C=0.01: 0.88656\n","Accuracy for C=0.05: 0.8936\n","Accuracy for C=0.25: 0.89632\n","Accuracy for C=0.5: 0.8968\n","Accuracy for C=1: 0.89648\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xRTNBfaOsYDD","executionInfo":{"status":"ok","timestamp":1617280895186,"user_tz":-480,"elapsed":110349,"user":{"displayName":"Cheng Fred","photoUrl":"","userId":"07264614451557710222"}},"outputId":"184570c7-a6e1-45c3-aa32-0a33f5751e09"},"source":["final_baseline2 = LogisticRegression(C=0.5) # taking c with highest accuracy\n","final_baseline2.fit(X_train, y_train)\n","print (\"Final Accuracy of Best Model: %s\" \n","       % accuracy_score(y_test, final_baseline2.predict(X_test)))\n","\n","print(\"Confusion Matrix of Best Model:\")\n","print(confusion_matrix(y_test, final_baseline2.predict(X_test)))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Final Accuracy of Best Model: 0.90224\n","Confusion Matrix of Best Model:\n","[[5562  662]\n"," [ 560 5716]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VeYCnUZUo9jX"},"source":["# Linear Support Vector Classification 1\n","Using:\n","1. 1 to 3 ngram\n","2. a simplier list of stop words\n","3. Linear Support Vector  "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vSM6flEPqLdI","executionInfo":{"status":"ok","timestamp":1617281122525,"user_tz":-480,"elapsed":162125,"user":{"displayName":"Cheng Fred","photoUrl":"","userId":"07264614451557710222"}},"outputId":"a4a4d378-9fdc-41c2-8afa-65773b69567c"},"source":["from sklearn.svm import LinearSVC\n","\n","stop_words = ['in', 'of', 'at', 'a', 'the'] # a more simple list of stop words\n","ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3), stop_words=stop_words) #using 1 to 3 ngrams\n","ngram_vectorizer.fit(reviews_train_clean)\n","train_set = ngram_vectorizer.transform(reviews_train_clean)\n","test_set = ngram_vectorizer.transform(reviews_test_clean)\n","\n","X_train = train_set\n","y_train = target\n","X_test, X_val, y_test, y_val = train_test_split(\n","      test_set, target, train_size = 0.5\n",")\n","\n","for c in [0.001, 0.005, 0.01, 0.05, 0.1]:\n","    \n","    svm = LinearSVC(C=c)\n","    svm.fit(X_train, y_train)\n","    print (\"Accuracy for C=%s: %s\" \n","           % (c, accuracy_score(y_val, svm.predict(X_val))))\n"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Accuracy for C=0.001: 0.89584\n","Accuracy for C=0.005: 0.90112\n","Accuracy for C=0.01: 0.9016\n","Accuracy for C=0.05: 0.9\n","Accuracy for C=0.1: 0.89928\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oKshE7J21XfW","executionInfo":{"status":"ok","timestamp":1617281156358,"user_tz":-480,"elapsed":2880,"user":{"displayName":"Cheng Fred","photoUrl":"","userId":"07264614451557710222"}},"outputId":"5202ee42-511f-462f-f354-9df505979ce2"},"source":["final_svm = LinearSVC(C=0.001) # taking c with highest accuracy\n","final_svm.fit(X_train, y_train)\n","print (\"Final Accuracy: %s\" \n","       % accuracy_score(y_test, final_svm.predict(X_test)))\n","\n","print(\"Confusion Matrix of Best Model:\")\n","print(confusion_matrix(y_test, final_svm.predict(X_test)))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Final Accuracy: 0.89576\n","Confusion Matrix of Best Model:\n","[[5539  689]\n"," [ 614 5658]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MScp0VIb2G-u"},"source":["# Linear Support Vector Classification 2\n","Using:\n","1. 1 to 3 ngram\n","2. a simplier list of stop words\n","3. Lemmatization\n","4. Linear Support Vector  "]},{"cell_type":"code","metadata":{"id":"Piab-AbqFKK9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617281325376,"user_tz":-480,"elapsed":164128,"user":{"displayName":"Cheng Fred","photoUrl":"","userId":"07264614451557710222"}},"outputId":"adb7846b-7006-48b0-dec5-4c5f409c25a2"},"source":["from sklearn.svm import LinearSVC\n","\n","stop_words = ['in', 'of', 'at', 'a', 'the'] # a more simple list of stop words\n","ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3), stop_words=stop_words) #using 1 to 3 ngrams\n","ngram_vectorizer.fit(lemmatized_reviews_train)\n","train_set = ngram_vectorizer.transform(lemmatized_reviews_train)\n","test_set = ngram_vectorizer.transform(lemmatized_reviews_test)\n","\n","X_train = train_set\n","y_train = target\n","X_test, X_val, y_test, y_val = train_test_split(\n","      test_set, target, train_size = 0.5\n",")\n","\n","for c in [0.001, 0.005, 0.01, 0.05, 0.1]:\n","    \n","    svm = LinearSVC(C=c)\n","    svm.fit(X_train, y_train)\n","    print (\"Accuracy for C=%s: %s\" \n","           % (c, accuracy_score(y_val, svm.predict(X_val))))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Accuracy for C=0.001: 0.89808\n","Accuracy for C=0.005: 0.902\n","Accuracy for C=0.01: 0.9024\n","Accuracy for C=0.05: 0.9032\n","Accuracy for C=0.1: 0.9024\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rOFrnQRUFJ-_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617281363120,"user_tz":-480,"elapsed":25073,"user":{"displayName":"Cheng Fred","photoUrl":"","userId":"07264614451557710222"}},"outputId":"146af953-20aa-4dcd-c5e9-fb615bcb4e0c"},"source":["final_svm2 = LinearSVC(C=0.05) # taking c=0.05 for highest accuracy\n","final_svm2.fit(X_train, y_train)\n","print (\"Final Accuracy: %s\" \n","       % accuracy_score(y_test, final_svm2.predict(X_test)))\n","\n","print(\"Confusion Matrix of Best Model:\")\n","print(confusion_matrix(y_test, final_svm2.predict(X_test)))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Final Accuracy: 0.898\n","Confusion Matrix of Best Model:\n","[[5529  688]\n"," [ 587 5696]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"y29PAJJi_KfT"},"source":["Experimented with linear models of logistic regression and Linear Support Vector Classification, both models gave similar performance, with accuracy close to 90%.\n","\n","Also, tried out both linear models with features after lemmatization. The results did not show lemmatization helps in improving accuracy greatly."]},{"cell_type":"code","metadata":{"id":"5ARY1QcWR32M","executionInfo":{"status":"ok","timestamp":1617281673214,"user_tz":-480,"elapsed":769,"user":{"displayName":"Cheng Fred","photoUrl":"","userId":"07264614451557710222"}}},"source":["# save \"final_baseline\" logistic regression model to disk\n","\n","Pkl_Filename = \"/content/drive/MyDrive/NLP_movie_review/final_baseline_lr.pkl\"  \n","\n","with open(Pkl_Filename, 'wb') as file:  \n","    pickle.dump(final_baseline, file)"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ASicgEnG6Ia1"},"source":["\n"]}]}